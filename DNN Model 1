# Importing necessary libraries for data analysis, visualization, and building the neural network model
import pandas as pd 
import matplotlib.pyplot as plt 
import numpy as np 

# Data preprocessing
from sklearn.preprocessing import MinMaxScaler 
from sklearn.model_selection import train_test_split 

# Keras and TensorFlow for building the neural network
from keras.models import Sequential 
from keras.layers import Dense, Dropout 
from keras.callbacks import EarlyStopping 
from keras.optimizers import Adam 
from tensorflow.keras import optimizers 

# Function to build Model 1 with two hidden layers
def build_model1_two_hidden_layers(train_dataset_scaled):
    # Initialize the Sequential model
    model = Sequential() 

    # Input Layer with 19 neurons, input shape based on the scaled training dataset
    model.add(Dense(19, input_shape=(train_dataset_scaled.shape[1],)))

    # Hidden Layer 1 with 50 neurons and ReLU activation function
    model.add(Dense(50, activation='relu'))

    # Hidden Layer 2 with 50 neurons and ReLU activation function
    model.add(Dense(50, activation='relu'))

    # Output Layer with 1 neuron (for regression)
    model.add(Dense(1)) 

    # Define the optimizer and learning rate
    learning_rate = 0.001
    optimizer = optimizers.RMSprop(learning_rate)

    # Compile the model with MSE loss and MAE, MSE, MAPE metrics for regression
    model.compile(loss='mse', 
                  optimizer=optimizer, 
                  metrics=['mae', 'mse', 'mape'])

    return model

# Function to train Model 1
def train_model1(model, train_dataset_scaled, train_labels, valid_dataset_scaled, valid_labels, EPOCHS=500, batch_size=32):
    # Train the model using the fit method
    history = model.fit(
        train_dataset_scaled,  # Scaled training dataset
        train_labels,  # Training labels
        batch_size=batch_size,  # Batch size
        epochs=EPOCHS,  # Number of epochs
        verbose=0,  # Suppress training progress output
        shuffle=True,  # Shuffle data during training
        steps_per_epoch=int(train_dataset_scaled.shape[0] / batch_size),  # Number of steps per epoch
        validation_data=(valid_dataset_scaled, valid_labels)  # Validation data
    )
    return history

# Function to display results after each epoch
def display_epoch_results(history):
    # Display a summary of the results after each epoch
    print('Summary of the results after each epoch: ') 
    hist = pd.DataFrame(history.history)  # Convert the history to a DataFrame
    hist['epoch'] = history.epoch  # Add epoch numbers to the DataFrame
    print(hist.tail())  # Display the last few rows of the summary

# Function to plot training and validation losses
def plot_loss(history): 
    # Plot training loss
    plt.plot(history.history['loss'], label='Training Loss')
    
    # Plot validation loss with log scale
    plt.plot(history.history['val_loss'], label='Validation Loss', linestyle='--')
    plt.yscale('log')  # Use logarithmic scale for the y-axis (validation loss)

    # Add labels and legend
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    
    # Show the plot
    plt.show()

# Function to plot true values vs predictions
def plot_true_vs_predicted(test_labels, test_predictions):
    a = plt.axes(aspect='equal') 
    plt.scatter(test_labels, test_predictions) 
    plt.xlabel('True Values [ROP]') 
    plt.ylabel('Predictions [ROP]')

    # Set axis limits
    lims = [-10, 60]
    plt.xlim(lims) 
    plt.ylim(lims)

    # Plot the ideal line (True Values = Predictions)
    _ = plt.plot(lims, lims)
    plt.show()

# Main function to integrate all steps
def model1(train_dataset_scaled, train_labels, valid_dataset_scaled, valid_labels, test_dataset_scaled, test_labels):
    # Build the model
    model = build_model1_two_hidden_layers(train_dataset_scaled)

    # Initialize and train the model
    history = train_model1(model, train_dataset_scaled, train_labels, valid_dataset_scaled, valid_labels)

    # Display results after each epoch
    display_epoch_results(history)

    # Plot training and validation losses
    plot_loss(history)

    # Make predictions on the test dataset
    test_predictions1 = model.predict(test_dataset_scaled).flatten()

    # Plot true values vs predictions
    plot_true_vs_predicted(test_labels, test_predictions1)

# Run Model 1 with your datasets (train, validation, and test datasets)
# Ensure that the following datasets are defined: 
# - train_dataset_scaled, train_labels
# - valid_dataset_scaled, valid_labels
# - test_dataset_scaled, test_labels
# model1(train_dataset_scaled, train_labels, valid_dataset_scaled, valid_labels, test_dataset_scaled, test_labels)
